# 优化算法  
机器学习中，有很多优化方法来试图寻找模型的最优解。  
## 梯度下降
##  动量
## 自适应学习率优化算法  
  自适应学习率优化算法针对于机器学习模型的学习率  
  目前的自适应学习率优化算法主要有：**AdaGrad算法**，**RMSProp算法**，**Adam算法**以及**AdaDelta算法**。
  - **AdaGrad**  
    - 思想  
      AdaGrad算法，独立地适应所有模型参数的学习率，缩放每个参数反比于其所有梯度历史平均值总和的平方根。具有代价函数最大梯度的参数相应地有个快速下降的学习率，而具有小梯度的参数在学习率上有相对较小的下降。
    - 算法描述
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEyMDk1OTI1MTMsLTg2MDUwMTQ2NCwtMj
k0NzAzODM4LDIzMjI5NjI4OV19
-->