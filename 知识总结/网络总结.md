**神经网络：**

神经网络技术起源于上世纪五、六十年代，当时叫感知机（perceptron），拥有输入层、输出层和（即但隐藏层的bp神经网络）。上世纪八十年代，发明的多层感知机。多层感知机，顾名思义，就是有多个隐含层的感知机。
 - **感知机**
感知机（perceptron）是二分类的线性分类模型，它的基本结构如图1所示，其输入为实例的特征向量，输出为实例的类别，取+1和-1二值，即使多个输入，一个输出。由输入空间到输出空间的如下函数 f(x)=sign(w·x+b)称为感知机。其中![enter image description here](https://github.com/sfxz035/DL-Learning/raw/master/picture/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20190318202610.png)。
![enter image description here](https://github.com/sfxz035/DL-Learning/raw/master/picture/%E6%84%9F%E7%9F%A5%E6%9C%BA.png)

	感知机模型选择的是采用随机梯度下降
 - **多层感知机(multi-layer perceptron)/神经网络(neural network)**
	
	多层感知机由感知机推广而来，最主要的特点是有多个神经元层，因此也叫深度神经网络(DNN: Deep Neural Networks)。
	多层感知机的一个重要特点就是多层，我们将第一层称之为输入层，最后一层称之有输出层，中间的层称之为隐层。MLP并没有规定隐层的数量，且对于输出层神经元的个数也没有限制。
![enter image description here](https://github.com/sfxz035/DL-Learning/raw/master/picture/11.png)

	1. 相比于感知器，引入了隐层(hidden layer)概念；隐层, 不包括输入层和输出层，在输入层和输出层中间的所有N层神经元就称作隐层！通常输入层不算作神经网络的一部分，对于有一层隐层的神经网络，叫做单隐层神经网络或二层感知机；对于第L个隐层，通常有以下一些特性：

		a) L层的每一个神经元与 L-1 层的每一个神经元的输出相连；

		b) L层的每一个神经元互相没有连接；

	2. 引入了新的非线性激活函数(sigmoid/tanh等)

	3. 反向传播算法(back propagation)

	4. 优化算法(梯度下降，随机梯度下降，mini-batch)-暂不确定

 - **卷积神经网络（CNN）**

	卷积神经网络的层级结构

		• 数据输入层/ Input layer
		• 卷积计算层/ CONV layer
		• ReLU激励层 / ReLU layer
		• 池化层 / Pooling layer
		• 全连接层 / FC layer

	小结：bp神经网络与卷积神经网络区别

### GoogleNet  
#### inception V1
- 网络结构  
  ![enter image description here](https://github.com/sfxz035/DL-Learning/raw/master/picture/3770010-28b5366b692d25d4.png)    
  其中，(a)是原版，(b)是改良版。  
  - 思想
- 特点分析
**ResNet网络**

结构：

优点：

为什么有效：

**UNet网络**

结构：

优点：

为什么有效：

**Min-batch:**

**SGD,ADAM区别**
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTExNDkzMTMwMjMsLTEyNzQwNDcxNzIsMT
EzOTYzNTc4MywtMTQ2NDYxMDIxMiwtMTI0Njk5MDQ1LC0xNzg0
NTIwMjU2LC0xNzA5MzI4MTM0LC00OTQxNTkxMjUsLTE1MDIzOT
Q0NDRdfQ==
-->