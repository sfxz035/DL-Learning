### 数据预处理
- **标准化**  
  数据标准化：**均值去除 和 按方差比例缩放**
  当单个特征的样本取值相差甚大或明显不遵从高斯正态分布时，标准化表现的效果较差。实际操作中，经常忽略特征数据的分布形状，移除每个特征均值，划分离散特征的标准差，从而等级化，进而实现数据中心化。  
  - 特点  
  对不同特征维度的伸缩变换的目的是使得不同度量之间的特征具有可比性。同时不改变原始数据的分布。  
  - 好处  
    1 使得不同度量之间的特征具有可比性，对目标函数的影响体现在几何分布上，而不是数值上    
    2 不改变原始数据的分布
   - 代码实现  
     - sklearn preprocessing  ---相当于z-score 标准化(zero-mean normalization)
       1. `preprocessing.scale(X)`  
	          ```
	          def scale(X, axis=0, with_mean=True, with_std=True,copy=True)```  
          参数解释：  
          X：{array-like, sparse matrix} 数组或者矩阵，一维的数据都可以（但是在0.19版本后一维的数据会报错了！）
    axis：int类型，初始值为0，axis用来计算均值 means 和标准方差 standard deviations.如果是0，则单独的标准化每个特征（列），如果是1，则标准化每个观测样本（行）。  
    with_mean: boolean类型，默认为True，表示将数据均值规范到0  
    with_std: boolean类型，默认为True，表示将数据方差规范到
       2.  `sklearn.preprocessing.StandardScaler()`  
          可保存训练集的标准化参数(均值、方差)，然后应用在转换测试集数据。 一般我们的标准化先在训练集上进行，在测试集上也应该做同样 mean 和 variance 的标准化
	          ```
	          scaler = preprocessing.StandardScaler().fit(X)
	          ```
       3. 自定义  
          ```x_norm = (x-np.min(x))/(np.max(x)-np.min(x))  ```
 - 归一化  
   **将数据特征缩放至某一范围**  
   - 特点  
     对不同特征维度的伸缩变换的目的是使各个特征维度对目标函数的影响权重是一致的，即使得那些扁平分布的数据伸缩变换成类圆形。这也就改变了原始数据的一个分布。
     
 - **两者区别**  
   参考[https://www.zhihu.com/question/20467170/answer/222792995](https://www.zhihu.com/question/20467170/answer/222792995)
<!--stackedit_data:
eyJoaXN0b3J5IjpbNTMyNTkxMzUyLC0xNDQ2Nzk0NTQsLTg3OT
U3NTUzOCwtNzEyMTgxNDAxLDEyNTQwMjk0MTksLTIwODg3NDY2
MTIsMTg0NDI5NTkzNCwtOTkzNTMwNDA3LDcwNDMwMDY2NiwtND
EyOTgxMzksMTI1MDY2NzgyNiwxMTQwOTcwMjc1LDcyNzkyMDI4
MCw5NTI0NTQzMTIsMTEwODQ4OTE1NiwtMTk2OTk5NTcwMiwxNT
c2NTIwMjAxLC0xMjQ5MTIzODQ1LC0yMDg4NzQ2NjEyXX0=
-->