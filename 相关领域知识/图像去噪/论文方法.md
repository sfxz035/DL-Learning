# 去噪方法

## 高斯白噪声去噪

#### 暂无

## 真实噪声去噪
#### DRDN: Dynamic Residual Dense Network for Image Denoising
- 简介   

  基于RDN（residual dense network）网络，RDB网络同通过级联多个RDBs（residual dense blocks）去充分利用多级特征。然而RDN只在单一的噪声等级上生效，RDN随着RDB的数量增多，计算量会显著增加，只会提高少量性能。   
  
  本文在RDB的基础上，加入了判断跳跃模块，对于每个RDBs进行判断，不重要则跳过，节省计算量，重要则进行计算。并且可以通过手动调整判断阈值的方法来调节网络去噪力度   
  
- 算法原理   
	- 实验理论  
	
	  文章作者通过可视化RDN网络中RDBs的输出特征图(不同通道特征图的平均值作为可视化结果输出)，发现一些相邻的特征图具有相似性，意味着RDBs是冗余的，故可通过修剪不必要的RDB减少计算量。而对于需要修剪的模块通过网络判断   
	  
	- 网络结构   
		
		训练时，当门模块输出为0时，对应的RDB不更新权重，门模块输出为1时，才更新权重。而无论门模块输出是什么，门模块内权重均更新。   
		推断时，由于网络仅执行前向传播，因此如果门模块的输出为0，则无需获取残差稠密块的输出。我们可以收集所有门模块的输出以计算残差块跳过的数量。 我们计算被跳过的块与总块的比率，这称为跳过比率。同时，可以通过**修改阈值t来改变跳过率和网络的去噪强度**。但是，由于阈值和跳过率不一致，因此我们使用简单的线性变换将阈值映射到跳过率：  
		$$t = \omega \lambda+(1-\omega)\epsilon$$  
		
	- 训练策略  
	   
	   损失函数定义为：   
	   
	   $$L = ||y-y_p||_1+\alpha \frac{1}{N}\sum_{d=1}^{N} {S_d(V_d)}$$  
	   
	   其中$S_d(V_d)$为门电路输出，N为门电路个数，y为label，yp为网络输出   
	   
	  1. 由于gate模块梯度传播的影响，需要简单的对DRDB进行预训练，以保证其具有去噪能力。先固定所有的gate模块为1，然后使用orthogonal matrix初始化卷积层参数。设置$\alpha$为0，因为gate模块不会参与决策  
	  2. 解除gate模块的固定，先初始化为一个接近0的值。在这一过程，让gate学习到提取有用的信息的能力。DRDN也可以进行二分决策  
	  3. 设置 $\alpha$为1e-4，让gate模块跳过更多的不重要的块。这时候我们没有有效引导gate做决策，因此这里需要激活loss函数的正则项，直接约束gate模块的输出。在这个步骤中，在skip ratio稳定后，学习率需要设置到更小，可以让模型获得更好的去噪能力   
	  4. (可选)Optional。作者还用强化学习作为第4个stage来训练gate模块，以进一步提高skip ratio。但是，在作者的实验中，强化学习可能会稍微恶化结果，并通过调整阈值来限制网络更改降噪强度的能力。相反，DRDN可以通过强化学习获得更高的跳过率。因此，作者将此阶段视为可选的训练阶段。  
	  
参考：https://zhuanlan.zhihu.com/p/87096400
## 盲去噪


## 其他
#### Noise2Noise
- **思想**   
  训练去噪模型无需干净的目标图，可以用带噪图代替。即网络通过两张同时获取的同噪声分布的噪声图(如连续短曝光两次获取)，训练得到与干净目标图同样的效果。  
- **理论依据**
	- 最小化损失  
	  
	  对于一系列不可靠观测值($y_1$，$y_2$，...)，输出预测值z，最小化损失函数如下：   
	  $${\underset {z}{\operatorname {arg\,min} }}\,E_y={L(z,y)}$$   
	  对于L2损失，最小化结果是观测值的算数平均值；L1损失，是观测值的中位数；   
	  
	- 网络表现   
	  
	  对于普通的回归任务来说，输入与输出之间不是简单的1：1映射，而是一对多映射。例如：超分中，一个低分辨率图片可能映射为多种不同的高分辨率图片。   

	  基于最小化损失的理论，使用L2损失训练一个回归神经网络，输入低分辨率图片，输出的高分辨率图片是所有可能输出的平均结果   
	
	- 应用延伸   
	
		基于以上的损失与网络的理论，在使用L2损失时，用与目标期望相同的随机数代替，不影响网络的训练效果(取决于样本数)  
		
		- 去噪	  
		
			用零均值的噪声图代替干净的目标图，不影响网络效果  

		- HDR  
		
			此处没看懂，涉及HDR图片去噪的损失选择  

		对于有限数据，输出方差为目标损坏的平均方差除以样本数，所以样本越多，带噪目标图的结果越接近于干净目标图结果。  

#### FFDNet

- 文章创新点
	- 引入噪声等级图作为网络输入，可以更加灵活的调整去噪力度，调节去噪与细节保留，并能适应空间变化噪声  
	
	- 为了提高去噪效率，对图像W×H×C进行降采样得到（W/2）×（H/2）×4C的子图像作为网络输入  
	
	- 采用正交初始化卷积，缓解因为噪声等级过大而引起的图像质量严重退化的问题，为了使噪声等级图更加鲁棒的调整去噪力度而不引起视觉artifacs  
	
	加上噪声等级图M后，网络的输入为（W/2）×（H/2）×（4C+1），M图中的元素是归一化后的$\sigma$  
	
#### CBDNet

本论文是作者继DnCNN和FFDNet之后的第三篇

- **本文的主要贡献分为以下几点**：
	-  提出了一个实际的噪声模型，考虑了异方差高斯噪声和相机内部的Pipline  
	
	- 验证了合成噪声图像和真实噪声图像构成的数据集比全部由真是噪声图像  构成的数据集表现的去噪性能好  
	
	- 引入噪声估计网络，非对称损失提高网络对于真实噪声图像的泛化能力，同时允许调节噪声等级图，灵活控制去噪力度  
		>  认为第三点比较关键，加入了可调性对于落地需求上比较重要，另外同时可以通过优化噪声等级图进一步优化去噪？
	


- **真实噪声模型**  

	- 背景  
	
		泊松高斯模型适用于Raw Image[1]。在[1][2]中相机响应函数(CRF)和量化噪声被考虑到了实际噪声建模中。相比于泊松-高斯模型，Hwang等人[3]提出了对于泊松相机噪声模型的Skellam分布。
		  
	    另外考虑RGB噪声模型的话，需要加入Image process pipline的影响，各通道噪声独立的假设或许不能保持，几个方法[4][5]提出了通道相关噪声模型建模。  
	    
	- 本文方法   
	
		- Raw 噪声模型  
		
		   泊松-高斯噪声模型   
		   
		- 未压缩ISP处理后噪声模型    
		
		  $y = f(DM(M^{-1}f^{-1}(x)+n(M^{-1}f^{-1}(x))))$   
		  x为干净图像，y为合成噪声图像，$f()$代表相机响应函数，$M^{-1}$为sRGB转换为bayer图函数，DM为demosaicing函数
		  
		- 压缩噪声模型   
		
			考虑JPEG压缩过程   
			
- 网络结构     

  CBDNet网络主要由两部分构成：噪声估计网络和非盲去噪网络     
  - 噪声估计网络   
  
     简单几层卷积层的堆叠，输出和图像大小一致的逐像素点的噪声等级图   
     
  - 去噪网络    
  
     残差Unet网络   
     
  - 损失函数    
     - 非对称损失函数
	     对于非盲去噪来说(例如BM3D和FFDNet)，输入的噪声等级与真实噪声等级一致时，去噪效果是最佳的；当输入噪声等级偏小的时候，去噪结果会有噪声残留；当输入噪声等级偏大的时候，依旧可以得到较好的结果。由此可以说明非盲去噪估计偏低的噪声等级参数比较敏感，而对于估计偏大的噪声等级参数更加鲁棒。因此在训练中可以利用这一点，使用非对称损失函数，约束较低的噪声等级参数。   
	       
	      对于估计的噪声等级$\hat{\sigma}(y_i)$和真实噪声等级$\sigma(y_i)$，定义以下损失：    
	      $$l_{asymm}=\sum_{i}{|\alpha-I_{\hat{\sigma}(y_i)-\sigma(y_i)<0}|\cdot{(\hat{\sigma}(y_i)-\sigma(y_i))}}$$   
	      当err<0时，$I=1$，否则$I=0$。设定$0<\alpha<0.5$，来更多地约束估计偏低。   
	  - TV损失   
	     
	     利用TV损失约束$\hat{\sigma}(y_i)$的平滑度   
	     $$L_{TV} = ||\nabla_h{\hat{\sigma}(y)}||^2_2+||\nabla_v{\hat{\sigma}(y)}||^2_2$$    
	     $\nabla_h$和$\nabla_v$代表水平和垂直方向梯度算子   
	     
	  - 重建损失  
	     
	    L2损失

	- 总损失   
	   $$L = L_{rec}+\lambda_{asymm}L_{asymm}+\lambda_{TV}L_{TV}$$     
	   
  - 数据集  
	  - NC12    
	  - DND  
	  - Nam  
  
  - 对比方法    
	  - 盲去噪：NC，NI，MCWNNM，TWSC
  
- 参考文献
	- [1]. Foi A, Trimeche M, Katkovnik V, et al. Practical Poissonian-Gaussian noise modeling and fitting for single-image raw-data[J]. IEEE Transactions on Image Processing, 2008, 17(10): 1737-1754.   
	- [2]. Liu C, Szeliski R, Kang S B, et al. Automatic estimation and removal of noise from a single image[J]. IEEE transactions on pattern analysis and machine intelligence, 2007, 30(2): 299-314.   
	- [3].  Hwang Y, Kim J S, Kweon I S. Difference-based image noise modeling using skellam distribution[J]. IEEE transactions on pattern analysis and machine intelligence, 2011, 34(7): 1329-1341.   
	- [4]. Seon Joo Kim, Hai Ting Lin, Zheng Lu, Sabine Susstrunk, ¨ Stephen Lin, and Michael S. Brown. A new in-camera imaging model for color computer vision and its application. IEEE Transactions on Pattern Analysis and Machine Intelligence, 34:2289–2302, 2012.      
	- [5]. Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala, and Timo Aila. Noise2noise: Learning image restoration without clean data. arXiv preprint arXiv:1803.04189, 2018.   
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTcwNTg5Mzk4OSwtMTE3NzY2OTM1OCwtMT
M2ODUxNjYzLC0xMDQxNDI2MTA5LC0yNjMxNTE5NTcsLTE5NzY3
NDM0ODMsLTUxMjY1NjM4OSwtNjE1NTA0NDMxLDExNDc2NzUxNT
ksMTIxMjA3MTEzNiwtMTA5MTI1MTExOSw4NTM5ODI5ODIsLTc0
NDczNjUxLDEzMTc3ODYwODMsLTE3OTY0MzU3MSwtNDA4MjE3Nj
ExLC0xNDk4ODUxODYyLC04ODYzMDc3NzAsMTIzNTE0NjQyMiwx
MDIxMjIxMjRdfQ==
-->