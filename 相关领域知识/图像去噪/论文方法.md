# 去噪方法

## 高斯白噪声去噪

#### 暂无

## 真实噪声去噪
#### DRDN: Dynamic Residual Dense Network for Image Denoising
- 简介

  基于RDN（residual dense network）网络，RDB网络同通过级联多个RDBs（residual dense blocks）去充分利用多级特征。然而RDN只在单一的噪声等级上生效，RDN随着RDB的数量增多，计算量会显著增加，只会提高少量性能。
  
  本文在RDB的基础上，加入了判断跳跃模块，对于每个RDBs进行判断，不重要则跳过，节省计算量，重要则进行计算。并且可以通过手动调整判断阈值的方法来调节网络去噪力度
  
- 算法原理
	- 实验理论
	
	  文章作者通过可视化RDN网络中RDBs的输出特征图(不同通道特征图的平均值作为可视化结果输出)，发现一些相邻的特征图具有相似性，意味着RDBs是冗余的，故可通过修剪不必要的RDB减少计算量。而对于需要修剪的模块通过网络判断
	  
	- 网络结构
		
		训练时，当门模块输出为0时，对应的RDB不更新权重，门模块输出为1时，才更新权重。而无论门模块输出是什么，门模块内权重均更新。
		推断时，由于网络仅执行前向传播，因此如果门模块的输出为0，则无需获取残差稠密块的输出。我们可以收集所有门模块的输出以计算残差块跳过的数量。 我们计算被跳过的块与总块的比率，这称为跳过比率。同时，可以通过**修改阈值t来改变跳过率和网络的去噪强度**。但是，由于阈值和跳过率不一致，因此我们使用简单的线性变换将阈值映射到跳过率：
		$$t = \omega \lambda+(1-\omega)\epsilon$$
		
	- 训练策略
	   
	   损失函数定义为：
	   
	   $$L = ||y-y_p||_1+\alpha \frac{1}{N}\sum_{d=1}^{N} {S_d(V_d)}$$
	   
	   其中$S_d(V_d)$为门电路输出，N为门电路个数，y为label，yp为网络输出
	   
	  1. 由于gate模块梯度传播的影响，需要简单的对DRDB进行预训练，以保证其具有去噪能力。先固定所有的gate模块为1，然后使用orthogonal matrix初始化卷积层参数。设置$\alpha$为0，因为gate模块不会参与决策
	  2. 解除gate模块的固定，先初始化为一个接近0的值。在这一过程，让gate学习到提取有用的信息的能力。DRDN也可以进行二分决策
	  3. 设置 $\alpha$为1e-4，让gate模块跳过更多的不重要的块。这时候我们没有有效引导gate做决策，因此这里需要激活loss函数的正则项，直接约束gate模块的输出。在这个步骤中，在skip ratio稳定后，学习率需要设置到更小，可以让模型获得更好的去噪能力
	  4. (可选)Optional。作者还用强化学习作为第4个stage来训练gate模块，以进一步提高skip ratio。但是，在作者的实验中，强化学习可能会稍微恶化结果，并通过调整阈值来限制网络更改降噪强度的能力。相反，DRDN可以通过强化学习获得更高的跳过率。因此，作者将此阶段视为可选的训练阶段。
	  
参考：https://zhuanlan.zhihu.com/p/87096400
## 盲去噪


## 其他
#### Noise2Noise
- **思想**
  训练去噪模型无需干净的目标图，可以用带噪图代替。即网络通过两张同时获取的同噪声分布的噪声图(如连续短曝光两次获取)，训练得到与干净目标图同样的效果。
- **理论依据**
	- 最小化损失
	  
	  对于一系列不可靠观测值($y_1$，$y_2$，...)，输出预测值z，最小化损失函数如下：
	  $${\underset {z}{\operatorname {arg\,min} }}\,E_y={L(z,y)}$$
	  对于L2损失，最小化结果是观测值的算数平均值；L1损失，是观测值的中位数；
	  
	- 网络表现
	  
	  对于普通的回归任务来说，输入与输出之间不是简单的1：1映射，而是一对多映射。例如：超分中，一个低分辨率图片可能映射为多种不同的高分辨率图片。

	  基于最小化损失的理论，使用L2损失训练一个回归神经网络，输入低分辨率图片，输出的高分辨率图片是所有可能输出的平均结果
	
	- 应用延伸
	
		基于以上的损失与网络的理论，在使用L2损失时，用与目标期望相同的随机数代替，不影响网络的训练效果(取决于样本数)
		
		- 去噪	
		
			用零均值的噪声图代替干净的目标图，不影响网络效果

		- HDR
		
			此处没看懂，涉及HDR图片去噪的损失选择

		对于有限数据，输出方差为目标损坏的平均方差除以样本数，所以样本越多，带噪目标图的结果越接近于干净目标图结果。

#### FFDNet

- 文章创新点
	- 引入噪声等级图作为网络输入，可以更加灵活的调整去噪力度，调节去噪与细节保留，并能适应空间变化噪声
	
	- 为了提高去噪效率，对图像W×H×C进行降采样得到（W/2）×（H/2）×4C的子图像作为网络输入  
	
	- 采用正交初始化卷积，缓解因为噪声等级过大而引起的图像质量严重退化的问题，为了使噪声等级图更加鲁棒的调整去噪力度而不引起视觉artifacs  
	
	加上噪声等级图M后，网络的输入为（W/2）×（H/2）×（4C+1），M图中的元素是归一化后的$\sigma$  
	
#### CBDNet

本论文是作者继DnCNN和FFDNet之后的第三篇

- 本文的主要贡献分为以下几点：
	-  提出了一个实际的噪声模型，考虑了异方差高斯噪声和相机内部的Pipline  
	
	- 验证了合成噪声图像和真实噪声图像构成的数据集比全部由真是噪声图像  构成的数据集表现的去噪性能好  
	
	- 引入噪声估计网络，非对称损失提高网络对于真实噪声图像的泛化能力，同时允许调节噪声等级图，灵活控制去噪力度  
	
	
CBDNet网络主要由两部分构成：噪声估计网络和非盲去噪网络  
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTQ4MTg0NTk4OCw4NTM5ODI5ODIsLTc0ND
czNjUxLDEzMTc3ODYwODMsLTE3OTY0MzU3MSwtNDA4MjE3NjEx
LC0xNDk4ODUxODYyLC04ODYzMDc3NzAsMTIzNTE0NjQyMiwxMD
IxMjIxMjQsLTE5MDMyNzIyNTUsNDUwOTkwNDg4LDQ1MDk5MDQ4
OCwxODgzMzI0NzI4LDk5ODAyMTQ4NiwxNjQzNzQ3NzgyLC0xMT
QzMzM5MzMyLDE3NTExMTAyMjMsLTIxMTYyMDcxODksLTI2NjYx
MjI4Nl19
-->