# 去噪方法

## 高斯白噪声去噪

## 真实噪声去噪
#### DRDN: Dynamic Residual Dense Network for Image Denoising
- 简介

  基于RDN（residual dense network）网络，RDB网络同通过级联多个RDBs（residual dense blocks）去充分利用多级特征。然而RDN只在单一的噪声等级上生效，RDN随着RDB的数量增多，计算量会显著增加，只会提高少量性能。
  
  本文在RDB的基础上，加入了判断跳跃模块，对于每个RDBs进行判断，不重要则跳过，节省计算量，重要则进行计算。并且可以通过手动调整判断阈值的方法来调节网络去噪力度
  
- 算法原理
	- 实验理论
	
	  文章作者通过可视化RDN网络中RDBs的输出特征图(不同通道特征图的平均值作为可视化结果输出)，发现一些相邻的特征图具有相似性，意味着RDBs是冗余的，故可通过修剪不必要的RDB减少计算量。而对于需要修剪的模块通过网络判断
	  
	- 网络结构
		推断时，由于网络仅执行前向传播，因此如果门模块的输出为0，则无需获取残差稠密块的输出。我们可以收集所有门模块的输出以计算残差块跳过的数量。 我们计算被跳过的块与总块的比率，这称为跳过比率。同时，可以通过修改阈值t来改变跳过率和网络的去噪强度。但是，由于阈值和跳过率不一致，因此我们使用简单的线性变换将阈值映射到跳过率：
		$$t = \omega \lambda+(1-\omega)\epsilon$$
	- 训练策略
- 
## 盲去噪


## 其他
#### Noise2Noise
- **思想**
  训练去噪模型无需干净的目标图，可以用带噪图代替。即网络通过两张同时获取的同噪声分布的噪声图(如连续短曝光两次获取)，训练得到与干净目标图同样的效果。
- **理论依据**
	- 最小化损失
	  
	  对于一系列不可靠观测值($y_1$，$y_2$，...)，输出预测值z，最小化损失函数如下：
	  $${\underset {z}{\operatorname {arg\,min} }}\,E_y={L(z,y)}$$
	  对于L2损失，最小化结果是观测值的算数平均值；L1损失，是观测值的中位数；
	  
	- 网络表现
	  
	  对于普通的回归任务来说，输入与输出之间不是简单的1：1映射，而是一对多映射。例如：超分中，一个低分辨率图片可能映射为多种不同的高分辨率图片。

	  基于最小化损失的理论，使用L2损失训练一个回归神经网络，输入低分辨率图片，输出的高分辨率图片是所有可能输出的平均结果
	
	- 应用延伸
	
		基于以上的损失与网络的理论，在使用L2损失时，用与目标期望相同的随机数代替，不影响网络的训练效果(取决于样本数)
		
		- 去噪	
		
			用零均值的噪声图代替干净的目标图，不影响网络效果

		- HDR
		
			此处没看懂，涉及HDR图片去噪的损失选择

		对于有限数据，输出方差为目标损坏的平均方差除以样本数，所以样本越多，带噪目标图的结果越接近于干净目标图结果。
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTQ1MTM0MjYzMywtMjExNjIwNzE4OSwtMj
Y2NjEyMjg2LDM5Mzc3MDk3NCwtMTAzNTU3MzM0Myw2ODU0MzIy
NTAsMjExNzExMjg3MywtMTk1MTgxNzQzNiwtMTQxNjM0MjM3NS
wtMTAyMTc5NDkyMSwtMTMyMDc4ODQ1MCw3MzA5OTgxMTZdfQ==

-->