## GAN
- 思想  
  Gan可以学习到loss。实际上本质上判别网络做的事情就是loss做的事情。因为一些情况，我们设置的loss并不是最贴切的情况，仍需要投入大量人力来设计有效的loss函数，所以希望网络自己取寻找最好的损失。
## CGAN  
- 原因  
 GAN这种不需要预先建模的方法缺点是太过自由了，对于较大的图片，较多的 pixel的情形，基于简单 GAN 的方式就不太可控了。为了解决GAN太过自由这个问题，一个很自然的想法是给GAN加一些约束   

## patch GAN  
 - 基于条件gan  
   条件体现在哪，怎么加入条件  
 - 方法  
   生成器除了输入，还可以加入条件输入。判别器判别时，也可以加入条件输入。   
   $LcGAN(G,D)=E_{x,y}[logD(x,y)]+E_{x,z}[log1−D(x,G(x,z))]$
 - 损失  
   用L1距离而不是L2距离，因为L1鼓励更少的模糊
   该网络对比了L1,GANloss,L1+GANloss损失效果，L1+GANloss效果最好。
 - 判别器结构  
   判别器结构使用全卷积网络，运用了patch的思想。  
   - 思想内容  
     **用来判别感受野是N×N的局部patch是真是假**。这个感受野举个例子，网络1x1大小的输出，他的感受野表示的是原图，含义是原图是真是假，这就是常规的判别器所用的。本文用的30x30大小的输出，他的每个元素感受野是70x70的patch,含义是原图中30个70x70的patch是真是假。最后一层每个像素过sigmoid输出为真的概率，然后用BCEloss计算得到最终loss。
   - 好处  
       这样做的好处是因为输入的维度大大降低，所以参数量少，运算速度也比直接输入一张快，并且可以计算任意大小的图。一些研究表明对于要求高分辨率、高清细节的图像领域中，普通GAN判别器并不适合，由此引入了PatchGAN，它的感受域对于与输入中的一小块区域，也就是说， 对应了判别器对输入图像的一小块的判别输出，这样训练使模型更能关注图像细节。  
    - 效果对比   
       论文对比了不同大小patch的结果，对于256x256的输入，patch大小在70x70的时候，从视觉上看结果就和直接把整张图片作为判别器输入没有多大区别了，但70x70速度更快。
## cycleGAN

<!--stackedit_data:
eyJoaXN0b3J5IjpbMzk5MDIxNjAsLTc0ODQxMTk4MSwxODM1Nz
cyMzE5LDI3NjgyMDkwLC0xMzI3ODgzMDY1LDQ1MDE5NDc5NCwt
MTM1MzEzMTQxOCwxNjMwOTc1NDY3LDExOTM4OTUwNTAsLTExOT
M1MTQ1ODcsOTU2NjcwMDA3XX0=
-->