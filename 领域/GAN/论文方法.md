## GAN
- 思想  
  Gan可以学习到loss。实际上本质上判别网络做的事情就是loss做的事情。因为一些情况，我们设置的loss并不是最贴切的情况，仍需要投入大量人力来设计有效的loss函数，所以希望网络自己取寻找最好的损失。
 - 局限性  
	 - 没有用户控制能力  
	 - 低分辨率（Low resolution）和低质量（Low quality）问题  
	   GAN生成的图片看起来很不错，但如果你放大看，就会发现**细节相当模糊**。

- 原始GAN形式的问题   
  - **判别器越好，生成器梯度消失越严重**  
  - **最小化第二种生成器loss函数，会等价于最小化一个不合理的距离衡量，导致两个问题，一是梯度不稳定，二是collapse mode即多样性不足**  
    
     第二种生成器损失指的是$E_{x-pg}[-log(D(x))]$  ,其中pg为生成器分布。（好像是该公式，待确定）   
 
  - **小结**：在原始GAN的（近似）最优判别器下，第一种生成器loss面临梯度消失问题，第二种生成器loss面临优化目标荒谬、梯度不稳定、对多样性与准确性惩罚不平衡导致mode collapse这几个问题。
  
## WGAN  
将损失问题优化为$D(G(X))-D(Y)$问题，并对真实样本和虚假样本进行加权抽样，进行梯度loss计算，从而限制。  
- 实施  
   ```
   epsilon = tf.random_uniform(shape = [self.batch_size, 1, 1, 1], minval = 0.0, maxval = 1.0)    
   interpolated_input = epsilon * label + (1 - epsilon) *self.gene_img    
   gradient = tf.gradients(self.discriminator(interpolated_input, reuse = True), [interpolated_input])[0]   
   GP_loss = tf.reduce_mean(tf.square(tf.sqrt(tf.reduce_mean(tf.square(gradient), axis = [1, 2, 3])) - 1))  
   d_loss_real = - tf.reduce_mean(self.real_prob)  
   d_loss_fake = tf.reduce_mean(self.fake_prob)  
   self.D_loss = d_loss_real + d_loss_fake + 10.0 * GP_loss
   ```  
   - 改进方面：  
     1. 判别器最后一层去掉sigmoid  
     2. 生成器和判别器的loss不取log  
     3. 每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c  
     4. 不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行
## CGAN  
- 原因  
 GAN这种不需要预先建模的方法缺点是太过自由了，对于较大的图片，较多的 pixel的情形，基于简单 GAN 的方式就不太可控了。为了解决GAN太过自由这个问题，一个很自然的想法是给GAN加一些约束   
- 主要内容  
  将原始GAN中的概率全改成了条件概率，  
  $\displaystyle\max _{D} \left \{  E_{x \sim P_{data}}logD(x|y)+E_{x \sim P_{G}}log(1-D(x|y))\right \}$  
  这个条件可以是图片，标注等等，结构如下图：  
  
  ## 此处缺图https://photos.app.goo.gl/oBPFEDwm5PvqakJ16  
  - 缺点  
    网络容易忽略输入，直接将条件作为唯一输入。 
## patch GAN(pix2pix)  
   用cGAN做image translation     
   
###  **方法**      
该方法使用的是**配对数据**。
  判别器判别时，除了输入生成器输出外，加入条件输入(这篇文章是加入生成器输入)，对判别器进行一个约束，从而达到对生成器的约束。使得生成器生成的结果与输入有一定的对应性。提高了用户控制能力。  
   其中z为输入，x为条件输入。
   $L_{cGAN}(G,D)=E_{x,y}[logD(x,y)]+E_{x,z}[log(1−D(x,G(x,z)))]$
### **损失**  
   用L1距离而不是L2距离，因为L1鼓励更少的模糊
   该网络对比了L1,GANloss,L1+GANloss损失效果，L1+GANloss效果最好。  
    判别器损失为交叉熵
### 网络结构  
网络结构如下图  
	此处缺图！
 - **生成器结构**  
   使用Unet作为生成器
 - **判别器结构**  
   判别器结构使用全卷积网络，运用了patch的思想。  
   - 思想内容  
     **用来判别感受野是N×N的局部patch是真是假**。这个感受野举个例子，网络1x1大小的输出，他的感受野表示的是原图，含义是原图是真是假，这就是常规的判别器所用的。本文用的30x30大小的输出，他的每个元素感受野是70x70的patch,含义是原图中30个70x70的patch是真是假。最后一层每个像素过sigmoid输出为真的概率，然后用BCEloss计算得到最终loss。
   - 好处  
       这样做的好处是因为输入的维度大大降低，所以参数量少，运算速度也比直接输入一张快，并且可以计算任意大小的图。一些研究表明对于要求高分辨率、高清细节的图像领域中，普通GAN判别器并不适合，由此引入了PatchGAN，它的感受域对于与输入中的一小块区域，也就是说， 对应了判别器对输入图像的一小块的判别输出，这样训练使模型更能关注图像细节。  
    - 效果对比   
       论文对比了不同大小patch的结果，对于256x256的输入，patch大小在70x70的时候，从视觉上看结果就和直接把整张图片作为判别器输入没有多大区别了，但70x70速度更快。
## cycleGAN  
   该网络针对非成对数据。   
   直接使用不成对的数据是不奏效的。网络会直接**忽略输入，随机产生输出**！所以，我们还得对网络增加**限制（constraint）**才行。所以该文章思想

## DeblurGAN  
- **本文贡献**  
  - 提出了损失和架构  
  - 提出了一种生成运动模糊数据的方法，并证明将其与现有的数据相结合可以获得更好的效果  
  - 提出了一种评估性能的方法
- **背景知识**  
  模糊问题分为两类，盲模糊和非盲模糊。非盲模糊为模糊核是已知的，盲模糊的模糊核是未知的。
- **损失**  
  对抗损失和MSE感知损失，MSE感知损失关注一般的内容，而对抗损失关注恢复纹理信息。    
  生成器损失为：VGG的MSE感知损失，判别器GAN损失  
  判别器损失为：WGAN损失+patch GAN判别器
- **网络结构**  
	- 生成器结构 
	  包含一个卷积核大小为7的卷积层，两个步长为2的卷积块，9个残差块和两个步长为2的反卷积块。每个残差块包含卷积层和IN,ReLU。每个残差块中第一个卷积层后面设置0.5的dropout。  
	  ![](https://github.com/sfxz035/DL-Learning/raw/master/picture/DeburGAN.png)    
	- 判别器结构  
	  运用patch gan的判别器结构 
-训练细节  
训练数据是裁剪的256x256的1000张图片。  
在$D_θ$上执行了5次梯度下降，在$G_θ$上执行了1次  
 - 问题  
   文章说此网络为条件GAN，条件体现在哪里？体现label上？
<!--stackedit_data:
eyJoaXN0b3J5IjpbNTMyMTA2NTMzLC0xNTg0ODMyMjkxLC0yMD
A3ODI5MzE0LDE4NTk1Nzc2MDcsLTE0Mzc0NjU5MjYsLTE5NDY0
OTIzMTcsMTExNzgwMTg4MSwtMTgxNDI4MTEzNCw2OTkyNzc3Nz
EsMjA2MDg4OTgyMiwxMjA0ODY0MTkzLC01NTU2NzY5NzQsNjU5
NDc1MjE3LDExMDE2MDg2MzEsNjg0ODI4NDMyLC0xMjU3OTgyMj
A4LC00MjQ2OTQ3MjIsLTkzMjQ2MDYyOCwtNzU3NDAxOTkxLC03
NDg0MTE5ODFdfQ==
-->