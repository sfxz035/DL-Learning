## GAN
- 思想  
  Gan可以学习到loss。实际上本质上判别网络做的事情就是loss做的事情。因为一些情况，我们设置的loss并不是最贴切的情况，仍需要投入大量人力来设计有效的loss函数，所以希望网络自己取寻找最好的损失。
## CGAN  
- 原因  
 GAN这种不需要预先建模的方法缺点是太过自由了，对于较大的图片，较多的 pixel的情形，基于简单 GAN 的方式就不太可控了。为了解决GAN太过自由这个问题，一个很自然的想法是给GAN加一些约束   

## patch GAN  
   基于条件gan   
 - **方法**    
  该方法使用的是配对数据。
  判别器判别时，除了输入生成器输出外，加入条件输入(这篇文章是加入生成器输入)，对判别器进行一个约束，从而达到对生成器的约束。使得生成器生成的结果与输入有一定的对应性。提高了用户控制能力。  
   其中z为输入，x为条件输入。
   $L_{cGAN}(G,D)=E_{x,y}[logD(x,y)]+E_{x,z}[log1−D(x,G(x,z))]$
 - **损失**  
   用L1距离而不是L2距离，因为L1鼓励更少的模糊
   该网络对比了L1,GANloss,L1+GANloss损失效果，L1+GANloss效果最好。
 - **判别器结构**  
   判别器结构使用全卷积网络，运用了patch的思想。  
   - 思想内容  
     **用来判别感受野是N×N的局部patch是真是假**。这个感受野举个例子，网络1x1大小的输出，他的感受野表示的是原图，含义是原图是真是假，这就是常规的判别器所用的。本文用的30x30大小的输出，他的每个元素感受野是70x70的patch,含义是原图中30个70x70的patch是真是假。最后一层每个像素过sigmoid输出为真的概率，然后用BCEloss计算得到最终loss。
   - 好处  
       这样做的好处是因为输入的维度大大降低，所以参数量少，运算速度也比直接输入一张快，并且可以计算任意大小的图。一些研究表明对于要求高分辨率、高清细节的图像领域中，普通GAN判别器并不适合，由此引入了PatchGAN，它的感受域对于与输入中的一小块区域，也就是说， 对应了判别器对输入图像的一小块的判别输出，这样训练使模型更能关注图像细节。  
    - 效果对比   
       论文对比了不同大小patch的结果，对于256x256的输入，patch大小在70x70的时候，从视觉上看结果就和直接把整张图片作为判别器输入没有多大区别了，但70x70速度更快。
## cycleGAN  
   该网络针对非成对数据。   
   直接使用不成对的数据是不奏效的。网络会直接**忽略输入，随机产生输出**！所以，我们还得对网络增加**限制（constraint）**才行。所以该文章思想

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEyNTc5ODIyMDgsLTQyNDY5NDcyMiwtOT
MyNDYwNjI4LC03NTc0MDE5OTEsLTc0ODQxMTk4MSwxODM1Nzcy
MzE5LDI3NjgyMDkwLC0xMzI3ODgzMDY1LDQ1MDE5NDc5NCwtMT
M1MzEzMTQxOCwxNjMwOTc1NDY3LDExOTM4OTUwNTAsLTExOTM1
MTQ1ODcsOTU2NjcwMDA3XX0=
-->