
### SRCNN
- **数据输入输出**  
   - 输入：SRCNN首先使用双三次(bicubic)插值将低分辨率图像放大成目标尺寸。(例如33x33)  
  - 输出：经卷积后的大小，卷积不进行padding。(例如33x33输入，输出21x21)  
  - 标签：作为标签数据的则为图像中心的21×21图像块（与卷积层细节设置相关）。  
> 测试时需将卷积模式改为padding
- **网络结构**  
  将3层网络划分为图像块提取(Patch extraction and representation)、非线性映射(Non-linear mapping)以及最终的重建(Reconstruction)。
  三层卷积神经网络，网络形式为(conv1+relu1)—(conv2+relu2)—(conv3)）。
  - 第一层卷积：卷积核尺寸9×9(f1×f1)，卷积核数目64(n1)，输出64张特征图；第二层卷积：卷积核尺寸1×1(f2×f2)，卷积核数目32(n2)，输出32张特征图；第三层卷积：卷积核尺寸5×5(f3×f3)，卷积核数目1(n3)。
- **问题**：  
  在本论文中的其中一实验相关设置，对YCrCb颜色空间中的Y通道进行重建。那么彩色图像应该怎么重建？所有彩色通道都重建？不同彩色模式对应的重建对象也不同？ 

### FSRCNN
- **针对SRCNN改进**：
	- SRCNN因为输入的是cheap interpolated LR image, 所以有很多冗余计算。  
	  FSRCNN直接输入低分辩图，不用插值。
	- SRCNN的Non-linear Mapping的参数量比较大  
	  FSRCNN改变特征维数，使用更小的卷积核和使用更多的映射层。
	 - 是可以共享其中的映射层，如果需要训练不同上采样倍率的模型，只需要fine-tuning最后的反卷积层。前面的特征提取和非线性映射都不用再训练。  
- **网络结构**  
	 - 特征提取层  
	     kernel size为5x5，输入通道1，输出特征通道数为d.
	 - 收缩  
	     用1x1卷积对LR feature降维, 减少后面的计算量。输入通道数d，输出s，s<<d。
	 - 非线性映射  
	     由m个3x3卷积层构成。特征通道数不变，为s。感受野大，表现的更好
	 - 扩张  
	     用1x1的卷积对特征维度进行上升，即增加特征通道数。输入通道数为s,输出为d。相当于收缩的反操作。  
	     >因为作者发现低纬度的HR feature的重建效果不好, 所以在mapping之后, 又用1x1 conv将HR feature升维, 类似Shrinking的反操作
	   
	 - 反卷积重建  
	     卷积核大小为9x9，输入通道数为d，输出通道数为1，实现上采样，进行尺寸放大。因为stride=k的conv卷积会将feature map缩小k倍, 所以stride为k的tranpose conv会将feature map放大k倍。
	 - 参数选择  
	     对比各种参数的结果，选取 m=4, d=56, s=12  
	  - 激活函数采用PReLU  
- 提升  
  1.  与SRCNN相比，速度提升了17到40倍（小型FSRCNN），在一般的CPU上实现了**实时性**。  
    原SRCNN在3倍 upsample  240×240240×240  图像时，帧率只有1.32。但实时性要求24fps，差17倍。  
    2.  恢复质量不减反升。
### ESPCN  
（本文同时实现了video和image的超分）  
- **输入输出**  
	- 输入：只取Y通道，归一化。直接输入低分辨率图片，不进行插值。  
	- 输出：输出高分辨率图片，实现网络的图片尺寸放大。  
 - **核心概念**  
   亚像素卷积层(sub-pixel convolutional layer)：  
   - 概念   
     网络的输入是原始低分辨率图像，通过最后一层卷积后，得到通道数为$r^2$的特征图。再将特征图每个像素的$r^2$个通道重新排列成一个rxr的区域，从而大小为 HxW的特征图像被重新排列成  (rH)x(rW)x1的高分辨率图像。由此图像尺寸放大了r倍。亚像素卷积层包含两个过程，一个普通的卷积层和后面的排列像素的步骤。最后一层卷积层输出的特征个数需要设置成固定值，即放大倍数r的平方。
   - 位置  
      本文并没有将**upscaling 放到CNN网络之中**，也是在网络的最末端设置了一个额外的 upscaling 层： **sub-pixel convolution layer**，从而将图片尺寸大小放大。  
      **卷积层最好不要在 HR space 上运作**，否则计算成本就会很高

### VDSR  
- **输入和输出**  
  - 输入：将插值后得到的变成目标尺寸的低分辨率图像作为网络的输入，同时将不同倍数的图像混合在一起输入训练。这样训练出来的一个模型就可以解决不同倍数的超分辨率问题（同一个模型学习多个尺度的放大）  
  - 输出：输出与输入尺寸大小相同。输出为高分辨图像。
- **关于多个倍数的分辨率问题**：  
  可以根据实验结果得出几点结论。
	1.  对于低倍数图像，用多尺度训练的网络几乎和用单尺度训练的网络一样
	2.  对于高倍数图像，采用多尺度训练的效果比采用单尺度训练的网络的效果好  
	
	原因是高倍数放大和低倍数放大有相似之处，它们间可以互相学习，尤其是高倍数的放大，能从低倍数放大的学习中额外获得新的信息，从而导致对于高倍数图像，采用多尺度训练的网络比采用单尺度训练的网络好。
- 网络结构  
  3x3卷积核叠加20层的全局残差网络结构。同时利用了梯度裁剪。  
  - 好处  
    收敛速度快：由于残差学习，需要学习的残差图像非常稀疏，大部分值都为0或者比较小，因此收敛速度快。  
    感受野大，效果好。  
  
### DRCN  
  - 网络结构  
    主要分为三个部分，第一部分是Embedding network，相当于SRCNN中的特征提取，二是Inference network，相当于特征的非线性变换，第三个是Reconstruction network，即特征图重建。  
    其中Inference network是一个递归层，即数据循环地通过该层多次，即D个共享参数的卷积层。然后将这D个卷积层的每一层的结果都通过相同的Reconstruction Net，在Reconstruction Net中与输入的图像相加，得到D个输出重建结果，将D个递归得到的结果再加权平均，得到总输出。  
	最终的目标函数就需要优化每一个递归层输出的误差和总输出的误差。  

### LapSRN    
- 论文中作者先总结了之前的方法存在有三点问题。
	- 一、有的方法在输入图像进网络前，需要使用预先定义好的上采样操作(例如bicubic)来获得目标的空间尺寸，这样的操作增加了额外的计算开销，同时也会导致可见的重建伪影。而有的方法使用了亚像素卷积层或者反卷积层这样的操作来替换预先定义好的上采样操作，这些方法的网络结构又相对比较简单，性能较差，并不能学好低分辨率图像到高分辨率图像复杂的映射。  
	- 二、在训练网络时使用MSE损失函数时，不可避免地会产生模糊的预测，恢复出的高分辨率图片往往会太过于平滑。  
	- 三、在重建高分辨率图像时，如果只用一次上采样的操作，在获得大倍数(8倍以上)的上采样因子时就会比较困难。而且在不同的应用时，需要训练不同上采样倍数的模型。针对这三点问题，作者提出了LapSRN    
- 网络结构  
   采用级联的网络结构（金字塔结构）：经过不断上采样，逐步进行超分辨，得到不同scale的图像。每次上采样学习到的参加，加上不同scale的低分辩图，得到不同scale的超分辨图。所有层级的输出均计算loss。对每一层都进行监督。   
 ### 各方法比较  
 ![enter image description here](https://github.com/sfxz035/DL-Learning/raw/master/picture/super.png)
### SRGAN   
超分辨中过于平滑的问题，MSE使重建结果有较高的信噪比，但是缺少了高频信息，出现过度平滑的纹理。该网络允许修复更高频信息
- **输入输出尺寸**  
  - 输入  
    输入不是经预处理到与HR图像同等尺寸大小的LR图像，是小尺寸的LR图像 
  - 输出经过上采样层得到  
    提高分辨率的上采样层，使用亚像素卷积层，得到HR图像。图像放大倍数决定于亚像素卷积层的scale大小。  
    - 预处理  
      对输入LR缩放到[0,1]，以及对应的HR缩放到[-1,1]   
 - **训练细节**  
   - **训练数据**  
     ImageNet数据库中，随机选取35万张图片作为训练数据，与测试数据不同。低分辩的图像是通过高分辨的图像(BGR,C=3)直接使用四倍双线性插值法降采样得到的。mini-batch截取16张96x96的HR图像的子图像(对图像切块)。
    - **网络构建**  
      **SRResnet（生成网络）**
       - 生成网络选取16个相同残差块。每个残差块包含两个卷积
	    - 激活函数  
      使用 Parametric ReLU 而不是 ReLU   
        - 两个2×亚像素卷积层(sub-pixel convolution layers)被用来增大特征尺寸  

	   **判别网络**  
         - 包含8个卷积层，随着网络层数加深，特征个数不断增加，特征尺寸不断减小
         - 激活函数  
           LReLU
         - 通过两个全连接层和最终的sigmoid激活函数得到预测为自然图像的概率  
       
       **图示**   
       ![enter image description here](https://github.com/sfxz035/DL-Learning/raw/master/picture/IHMG0%25%7BPK@5FMJ%28J7WJY8B6.png)   
       
 - **损失**   
   - 生成器损失 
   该网络损失定义了一种感知损失作为生成器损失 G loss 分为 内容loss 和 对抗网络loss，内容loss又分为mse loss和vgg loss
		- 感知损失   
	  ![enter image description here](https://github.com/sfxz035/DL-Learning/raw/master/picture/20180908095427715.png)
		  - 内容损失  
		    - MSE     
		    ![enter image description here](https://github.com/sfxz035/DL-Learning/raw/master/picture/80%29PJ@%606YYKISH%60%7B%60%6051YWB.png)  
		    - VGG  
		      ![enter image description here](https://github.com/sfxz035/DL-Learning/raw/master/picture/CW454WUJP~%25W%60ZP45~YDZZC.png)     
		   - 对抗损失  
		     ![enter image description here](https://github.com/sfxz035/DL-Learning/raw/master/picture/_5U%28NT~7@%60HCR%7B9NIF6X4Z2.png) 
	- 鉴别器损失  
- 网络特点  
    针对问题： 训练网络时用均方差作为损失函数，虽然能够获得很高的峰值信噪比，但是恢复出来的图像通常会丢失高频细节，出现过度平滑的纹理，使人不能有好的视觉感受。   
    - 解决方法
	    - SRGAN利用感知损失(perceptual loss)和对抗损失(adversarial loss)来提升恢复出的图片的真实感。 
		    - 基于特征空间的最小均方差损失：利用VGG网络提取图像高层次特征，通过比较生成图片经过卷积神经网络后的特征和目标图片经过卷积神经网络后的特征的差别，使生成图片和目标图片在语义和风格上更相似。
	    - 通过鉴别器，是生成图片具有更逼真的视觉效果。
 
###  EDSR  
相比较SRResnet，EDSR去掉了BN层  
- **训练细节**
	- 输入输出  
	    输入输出为RGB的三通道图像块，48x48x3，输出(48xscale)x(48xscale)x3。对输入图像,目标图像进行预处理，所有图片减去一个均值。( We pre-process all the images by subtracting the mean RGB value of the DIV2K dataset）
	- 网络参数  
        在最终单尺度模型EDSR中，通过设置B=32个残差块，F=256个通道。
	- 损失  
	    使用L1损失  
	- 网络结构  
	    先conv,接32个残差模块，接conv,和第一层conv输出相加，进行上采样，接conv，输出。上采样前，通道数均为256。
	    - 残差块   
	    残差缩放，对残差快内最后一个卷积的结果皆乘以一个缩放因子，文章中为0.1  
	    ![enter image description here](https://github.com/sfxz035/DL-Learning/raw/master/picture/block.png)
	    - 网络结构图   
	      ![enter image description here](https://github.com/sfxz035/DL-Learning/raw/master/picture/EDSR.png)
- 残差缩放的意义   
  提高网络模型性能的最简单方法是增加参数数量。**增加宽度(特征Channels的数量)F**。  
  
  特征图的数量增加(太多的残差块)到一定水平以上会使训练过程在数值上不稳定。  
  
  残差缩放(residual scaling)即残差块在相加前，经过卷积处理的一路乘以一个小数(作者用了0.1)    
  
  每个残差块中，在最后的卷积层之后放置恒定的缩放层。使用大量滤波器时，这些模块极大地稳定了训练过程。
- BN  
  Batch Norm可谓深度学习中非常重要的技术，不仅可以使训练更深的网络变容易，加速收敛，还有一定正则化的效果，可以防止模型过拟合。在很多基于CNN的分类任务中，被大量使用。 但在图像超分辨率和图像生成方面，Batch Norm的表现并不好，加入了Batch Norm，反而使得训练速度缓慢，不稳定，甚至最后发散。以图像超分辨率来说，网络输出的图像在色彩、对比度、亮度上要求和输入一致，改变的仅仅是分辨率和一些细节，而Batch Norm，对图像来说类似于一种对比度的拉伸，任何图像经过Batch Norm后，其色彩的分布都会被归一化，也就是说，它破坏了图像原本的对比度信息，所以Batch Norm的加入反而影响了网络输出的质量。虽然Batch Norm中的scale和shift参数可以抵消归一化的效果，但这样就增加了训练的难度和时间，还不如直接不用。不过有一类网络结构可以用，那就是残差网络（Residual Net），但也仅仅是在residual block当中使用，比如SRResNet，就是一个用于图像超分辨率的残差网络。为什么这类网络可以使用Batch Norm呢？有人认为是因为图像的对比度信息可以通过skip connection直接传递，所以也就不必担心Batch Norm的破坏了。 	基于这种想法，也可以从另外一种角度解释Batch Norm为何在图像分类任务上如此有效。图像分类不需要保留图像的对比度信息，利用图像的结构信息就可以完成分类，所以，将图像都通过Batch Norm进行归一化，反而降低了训练难度，甚至一些不明显的结构，在Batch Norm后也会被凸显出来（对比度被拉开了）。	而对于照片风格转移，为何可以用Batch Norm呢？原因在于，风格化后的图像，其色彩、对比度、亮度均和原图像无关，而只与风格图像有关，原图像只有结构信息被表现到了最后生成的图像中。因此，在照片风转移的网络中使用Batch Norm或者Instance Norm也就不奇怪了，而且，Instance Norm是比Batch Norm更直接的对单幅图像进行的归一化操作，连scale和shift都没有。

	说得更广泛一些，Batch Norm会忽略图像像素（或者特征）之间的绝对差异（因为均值归零，方差归一），而只考虑相对差异，所以在不需要绝对差异的任务中（比如分类），有锦上添花的效果。而对于图像超分辨率这种需要利用绝对差异的任务，Batch Norm只会添乱。

### RDN


### 问题  
- 不进行插值，直接将图片输入网络中的情况，如何找寻低分辩率在高分辨率图像上对应的图像块。  
- 我们使用He等人【13】的方法初始化卷积滤波器。**转置卷积滤波器的大小是4× 4，权重是从一个双线性滤波器（a bilinear filter）中初始化的**???He的方法是什么？双线性滤波器如何初始化反卷积  
- 下采样可能会丢失细节信息，所以超分辨一般不用pooling？RED这个网络的下采样是通过完全卷积实现的，并且除了超分还有去噪的功能，在去噪的过程中会失去一些细节信息。那skip connetion有用么？？？  
RED网络(上采样，下采样)：首先，在完全卷积的情况下，逐步消除噪声，即在每层之后降低噪声水平。在此过程中，图像内容的细节可能会丢失。然而，在我们的网络中，卷积保留了主要图像内容。然后使用去卷积来补偿细节。  
	- skip connetion   
	  一个直观的问题是，解卷积是否只能从图像抽象中恢复图像细节？我们发现在只有几层卷积的浅层网络中，反卷积能够恢复细节。但是，当网络更深或使用最大池等操作时，解卷积不能很好地工作，可能是因为卷积中已经丢失了太多的图像细节。当网络变得更深时，如上所述，图像细节可能会丢失，使得反卷积在恢复它们时变得更弱。但是，跳过连接传递的特征映射带有很多图像细节，这有助于解卷积以恢复更好的清晰图像。
格

- 超分辨总结  
  - 评价指标PSNR并不是一个很好的评价指标，SRGAN的视觉效果好，但PSNR并不比其他方法高。
  - MSEloss 容易使输出的图像过于平滑，细节部分信息恢复不好，SRGAN在这点上比较好，恢复出图片视觉效果好，不会过于平滑，但PSNR比其他方法低。 
  - 上采样问题，如何设计网络部分的上采样可以是超分辨效果更好是一个方向  
  - 池化，BN层，在超分网络中并不常用，因为池化会损失细节部分信息，而对于超分任务来说，细节信息很重要，BN层则会打乱原有图像的对比度，亮度等，不利于超分。（待重新总结完善） 
  - 超分的网络输入也是一个问题，一个方法是，先在网络之外将原始的LR（Low Resolution）的图像通过插值法扩大到MR级别的图像，再将MR图像输入网络。这种方法有一个问题，就是有可能在插值过程中向图像中加入新的噪声。
 
 - 总结未解决问题  
   对于各种色彩空间的图片应该怎么处理，比如RGB,BGR等应该怎么输入，Y单通道输入是什么色彩空间。PSNR的计算彩色通道怎么计算？影响么？


<!--stackedit_data:
eyJoaXN0b3J5IjpbLTgzMjM3MTk3OCwyMTg4MDEzOTYsMTYxNT
YzNDExMCwyNDE4ODAzMDQsNzk3Mzk4OTMwLDE1NDU0NzA0MTgs
Njc2NTY2MDEyLC0xODQ3NjYzNzA3LC0xNjkzNDU2NTY5LDQxOT
U3NTY2OCwtMTI0OTU1NDk3Miw0NzU1NzMzNjgsMTQwNTA0NzI4
MSw2NTMyMjI3MCw2ODg1NTIwMiw1MTU3OTEyMTksODMzNTAzMD
I3LC0xMzY3MjYzNzc2LDExODg5MDU3MjAsNzY0MTc2NDg2XX0=

-->