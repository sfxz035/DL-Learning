
### SRCNN
- **数据输入输出**  
   - 输入：SRCNN首先使用双三次(bicubic)插值将低分辨率图像放大成目标尺寸。(例如33x33)  
  - 输出：经卷积后的大小，卷积不进行padding。(例如33x33输入，输出21x21)  
  - 标签：作为标签数据的则为图像中心的21×21图像块（与卷积层细节设置相关）。  
> 测试时需将卷积模式改为padding
- **网络结构**  
  将3层网络划分为图像块提取(Patch extraction and representation)、非线性映射(Non-linear mapping)以及最终的重建(Reconstruction)。
  三层卷积神经网络，网络形式为(conv1+relu1)—(conv2+relu2)—(conv3)）。
  - 第一层卷积：卷积核尺寸9×9(f1×f1)，卷积核数目64(n1)，输出64张特征图；第二层卷积：卷积核尺寸1×1(f2×f2)，卷积核数目32(n2)，输出32张特征图；第三层卷积：卷积核尺寸5×5(f3×f3)，卷积核数目1(n3)。
- **问题**：  
  在本论文中的其中一实验相关设置，对YCrCb颜色空间中的Y通道进行重建。那么彩色图像应该怎么重建？所有彩色通道都重建？不同彩色模式对应的重建对象也不同？ 

### FSRCNN
- **针对SRCNN改进**：
	- SRCNN因为输入的是cheap interpolated LR image, 所以有很多冗余计算。  
	  FSRCNN直接输入低分辩图，不用插值。
	- SRCNN的Non-linear Mapping的参数量比较大  
	  FSRCNN改变特征维数，使用更小的卷积核和使用更多的映射层。
	 - 是可以共享其中的映射层，如果需要训练不同上采样倍率的模型，只需要fine-tuning最后的反卷积层。前面的特征提取和非线性映射都不用再训练。  
- **网络结构**  
	 - 特征提取层  
	     kernel size为5x5，输入通道1，输出特征通道数为d.
	 - 收缩  
	     用1x1卷积对LR feature降维, 减少后面的计算量。输入通道数d，输出s，s<<d。
	 - 非线性映射  
	     由m个3x3卷积层构成。特征通道数不变，为s。感受野大，表现的更好
	 - 扩张  
	     用1x1的卷积对特征维度进行上升，即增加特征通道数。输入通道数为s,输出为d。相当于收缩的反操作。  
	     >因为作者发现低纬度的HR feature的重建效果不好, 所以在mapping之后, 又用1x1 conv将HR feature升维, 类似Shrinking的反操作
	   
	 - 反卷积重建  
	     卷积核大小为9x9，输入通道数为d，输出通道数为1，实现上采样，进行尺寸放大。因为stride=k的conv卷积会将feature map缩小k倍, 所以stride为k的tranpose conv会将feature map放大k倍。
	 - 参数选择  
	     对比各种参数的结果，选取 m=4, d=56, s=12  
	  - 激活函数采用PReLU  
- 提升  
  1.  与SRCNN相比，速度提升了17到40倍（小型FSRCNN），在一般的CPU上实现了**实时性**。  
    原SRCNN在3倍 upsample  240×240240×240  图像时，帧率只有1.32。但实时性要求24fps，差17倍。  
    2.  恢复质量不减反升。
### ESPCN  
（本文同时实现了video和image的超分）  
- **输入输出**  
	- 输入：只取Y通道，归一化。直接输入低分辨率图片，不进行插值。  
	- 输出：输出高分辨率图片，实现网络的图片尺寸放大。  
 - **核心概念**  
   亚像素卷积层(sub-pixel convolutional layer)：  
   - 概念   
     网络的输入是原始低分辨率图像，通过最后一层卷积后，得到通道数为$r^2$的特征图。再将特征图每个像素的$r^2$个通道重新排列成一个rxr的区域，从而大小为 HxW的特征图像被重新排列成  (rH)x(rW)x1的高分辨率图像。由此图像尺寸放大了r倍。亚像素卷积层包含两个过程，一个普通的卷积层和后面的排列像素的步骤。最后一层卷积层输出的特征个数需要设置成固定值，即放大倍数r的平方。
   - 位置  
      本文并没有将**upscaling 放到CNN网络之中**，也是在网络的最末端设置了一个额外的 upscaling 层： **sub-pixel convolution layer**，从而将图片尺寸大小放大。  
      **卷积层最好不要在 HR space 上运作**，否则计算成本就会很高

### VDSR  
- **输入和输出**  
  - 输入：将插值后得到的变成目标尺寸的低分辨率图像作为网络的输入，同时将不同倍数的图像混合在一起输入训练。这样训练出来的一个模型就可以解决不同倍数的超分辨率问题（同一个模型学习多个尺度的放大）  
  - 输出：输出与输入尺寸大小相同。输出为高分辨图像。
- 关于多个倍数的分辨率问题：  
  可以根据实验结果得出几点结论。
	1.  对于低倍数图像，用多尺度训练的网络几乎和用单尺度训练的网络一样
	2.  对于高倍数图像，采用多尺度训练的效果比采用单尺度训练的网络的效果好  
	
	原因是高倍数放大和低倍数放大有相似之处，它们间可以互相学习，尤其是高倍数的放大，能从低倍数放大的学习中额外获得新的信息，从而导致对于高倍数图像，采用多尺度训练的网络比采用单尺度训练的网络好。
- 网络结构  
  3x3卷积核叠加20层的全局残差网络结构。同时利用了梯度裁剪。  
  - 好处  
    收敛速度快：由于残差学习，需要学习的残差图像非常稀疏，大部分值都为0或者比较小，因此收敛速度快。  
    感受野大，效果好。  
  
  ### DRCN  
  - 网络结构  
    主要分为三个部分，第一部分是Embedding network，相当于SRCNN中的特征提取，二是Inference network，相当于特征的非线性变换，第三个是Reconstruction network，即特征图重建。  
    其中Inference network是一个递归层，即数据循环地通过该层多次，即D个共享参数的卷积层。然后将这D个卷积层的每一层的结果都通过相同的Reconstruction Net，在Reconstruction Net中与输入的图像相加，得到D个输出重建结果，将D个递归得到的结果再加权平均，得到总输出。  
	最终的目标函数就需要优化每一个递归层输出的误差和总输出的误差。  

### LapSRN    
论文中作者先总结了之前的方法存在有三点问题。一是有的方法在输入图像进网络前，需要使用预先定义好的上采样操作(例如bicubic)来获得目标的空间尺寸，这样的操作增加了额外的计算开销，同时也会导致可见的重建伪影。而有的方法使用了亚像素卷积层或者反卷积层这样的操作来替换预先定义好的上采样操作，这些方法的网络结构又相对比较简单，性能较差，并不能学好低分辨率图像到高分辨率图像复杂的映射。二是在训练网络时使用  型损失函数时，不可避免地会产生模糊的预测，恢复出的高分辨率图片往往会太过于平滑。三是在重建高分辨率图像时，如果只用一次上采样的操作，在获得大倍数(8倍以上)的上采样因子时就会比较困难。而且在不同的应用时，需要训练不同上采样倍数的模型。针对这三点问题，作者提出了LapSRN  

### SRResnet    
超分辨中过于平滑的问题，MSE使重建结果有较高的信噪比，但是缺少了高频信息，出现过度平滑的纹理？？超分辨BN层的问题？？
###  EDSR

### RDN


### 问题  
对于不进行插值，直接将图片输入网络中的情况，如何找寻低分辩率在高分辨率图像上对应的图像块。
<!--stackedit_data:
eyJoaXN0b3J5IjpbNjY2MDk5NTkyLC00NTUxMDU4OTQsMTAyNT
cwODk3LC0yNDE2MTA4MCwtNzM0NDg4OTMwLDE5ODI3NzY2NzIs
NTQyMTk0MDk4LDgzNTUwODA1NCwtNTAzNTIwMzA4LDE0NjEwOT
YyODUsODc0MjYwODA5LC01MTU2MzgyNTYsMTIwMDUyNzIyOCw3
MTIxOTExODIsLTk3MTE2MDUwOCw0OTk1NzM1MDUsMTk2NDcyMT
QxLDE0MDU5NDM3MDQsLTQ2ODkyNzczMiwtMTk3ODUxMjI4MF19

-->