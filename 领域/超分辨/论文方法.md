
### SRCNN
- **数据输入输出**  
   - 输入：SRCNN首先使用双三次(bicubic)插值将低分辨率图像放大成目标尺寸。(例如33x33)  
  - 输出：经卷积后的大小，卷积不进行padding。(例如33x33输入，输出21x21)  
  - 标签：作为标签数据的则为图像中心的21×21图像块（与卷积层细节设置相关）。  
> 测试时需将卷积模式改为padding
- **网络结构**  
  将3层网络划分为图像块提取(Patch extraction and representation)、非线性映射(Non-linear mapping)以及最终的重建(Reconstruction)。
  三层卷积神经网络，网络形式为(conv1+relu1)—(conv2+relu2)—(conv3)）。
  - 第一层卷积：卷积核尺寸9×9(f1×f1)，卷积核数目64(n1)，输出64张特征图；第二层卷积：卷积核尺寸1×1(f2×f2)，卷积核数目32(n2)，输出32张特征图；第三层卷积：卷积核尺寸5×5(f3×f3)，卷积核数目1(n3)。
- **问题**：  
  在本论文中的其中一实验相关设置，对YCrCb颜色空间中的Y通道进行重建。那么彩色图像应该怎么重建？所有彩色通道都重建？不同彩色模式对应的重建对象也不同？ 

### FSRCNN
- **针对SRCNN改进**：
	- SRCNN因为输入的是cheap interpolated LR image, 所以有很多冗余计算。  
	  FSRCNN直接输入低分辩图，不用插值。
	- SRCNN的Non-linear Mapping的参数量比较大  
	  FSRCNN改变特征维数，使用更小的卷积核和使用更多的映射层。
	 - 是可以共享其中的映射层，如果需要训练不同上采样倍率的模型，只需要fine-tuning最后的反卷积层。前面的特征提取和非线性映射都不用再训练。  
- **网络结构**  
	 - 特征提取层  
	     kernel size为5x5，输入通道1，输出特征通道数为d.
	 - 收缩  
	     用1x1卷积对LR feature降维, 减少后面的计算量。输入通道数d，输出s，s<<d。
	 - 非线性映射  
	     由m个3x3卷积层构成。特征通道数不变，为s。感受野大，表现的更好
	 - 扩张  
	     用1x1的卷积对特征维度进行上升，即增加特征通道数。输入通道数为s,输出为d。相当于收缩的反操作。  
	     >因为作者发现低纬度的HR feature的重建效果不好, 所以在mapping之后, 又用1x1 conv将HR feature升维, 类似Shrinking的反操作
	   
	 - 反卷积重建  
	     卷积核大小为9x9，输入通道数为d，输出通道数为1，实现上采样，进行尺寸放大。因为stride=k的conv卷积会将feature map缩小k倍, 所以stride为k的tranpose conv会将feature map放大k倍。
	 - 参数选择  
	     对比各种参数的结果，选取 m=4, d=56, s=12  
	  - 激活函数采用PReLU  
- 提升  
  1.  与SRCNN相比，速度提升了17到40倍（小型FSRCNN），在一般的CPU上实现了**实时性**。  
    原SRCNN在3倍 upsample  240×240240×240  图像时，帧率只有1.32。但实时性要求24fps，差17倍。  
    2.  恢复质量不减反升。
### ESPCN  
（本文同时实现了video和image的超分）  
- **输入输出**  
	- 输入：只取Y通道，归一化。直接输入低分辨率图片，不进行插值。  
	- 输出：输出高分辨率图片，实现网络的图片尺寸放大。  
 - **核心概念**  
   亚像素卷积层(sub-pixel convolutional layer)：  
   - 概念   
     网络的输入是原始低分辨率图像，通过最后一层卷积后，得到通道数为$r^2$的特征图。再将特征图每个像素的$r^2$个通道重新排列成一个rxr的区域，从而大小为 HxW的特征图像被重新排列成  (rH)x(rW)x1的高分辨率图像。由此图像尺寸放大了r倍。亚像素卷积层包含两个过程，一个普通的卷积层和后面的排列像素的步骤。最后一层卷积层输出的特征个数需要设置成固定值，即放大倍数r的平方。
   - 位置  
      本文并没有将**upscaling 放到CNN网络之中**，也是在网络的最末端设置了一个额外的 upscaling 层： **sub-pixel convolution layer**，从而将图片尺寸大小放大。  
      **卷积层最好不要在 HR space 上运作**，否则计算成本就会很高

### VDSR  
- **输入和输出**  
  - 输入：将插值后得到的变成目标尺寸的低分辨率图像作为网络的输入，同时将不同倍数的图像混合在一起输入训练。这样训练出来的一个模型就可以解决不同倍数的超分辨率问题（同一个模型学习多个尺度的放大）  
  - 输出：输出与输入尺寸大小相同。输出为高分辨图像。
- 关于多个倍数的分辨率问题：  
  可以根据实验结果得出几点结论。
	1.  对于低倍数图像，用多尺度训练的网络几乎和用单尺度训练的网络一样
	2.  对于高倍数图像，采用多尺度训练的效果比采用单尺度训练的网络的效果好
<!--stackedit_data:
eyJoaXN0b3J5IjpbNzI1NzMyMjU1LDEyMDA1MjcyMjgsNzEyMT
kxMTgyLC05NzExNjA1MDgsNDk5NTczNTA1LDE5NjQ3MjE0MSwx
NDA1OTQzNzA0LC00Njg5Mjc3MzIsLTE5Nzg1MTIyODAsNDI2MT
I5NTU0LC00OTM3OTA2NzcsLTkzODA4NDM0NSwzODQ0NzQ2NDIs
LTE2NjkzODk0ODcsOTM0NzU0MTAyLDI1MzAwNjc2OCwyMDQwMj
k3NjIyXX0=
-->